{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markupsafe import escape\n",
    "from selenium import webdriver\n",
    "from thesentiment import sentiment\n",
    "from collections import Counter\n",
    "import re\n",
    "import csv\n",
    "from getpass import getpass\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "from google_trans_new import google_translator\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_data(card):\n",
    "    \"\"\"Extract data from tweet card\"\"\"\n",
    "    username = card.find_element_by_xpath('.//span').text\n",
    "    try:\n",
    "        handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "\n",
    "    comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "    responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "\n",
    "    text = comment + responding\n",
    "\n",
    "    reply_cnt = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    retweet_cnt = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    like_cnt = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    tweet = (username, handle, postdate, text, reply_cnt, retweet_cnt, like_cnt)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d5bd9e4fec90>:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n",
      "<ipython-input-6-d5bd9e4fec90>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  username = driver.find_element_by_xpath('//input[@name=\"username\"]')\n",
      "<ipython-input-6-d5bd9e4fec90>:19: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  password = driver.find_element_by_xpath('//input[@name=\"password\"]')\n",
      "<ipython-input-6-d5bd9e4fec90>:23: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  email = driver.find_element_by_xpath('//input[@name=\"text\"]')\n",
      "<ipython-input-6-d5bd9e4fec90>:27: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  password = driver.find_element_by_xpath('//input[@name=\"password\"]')\n",
      "<ipython-input-6-d5bd9e4fec90>:37: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_input = driver.find_element_by_xpath('//input[@data-testid=\"SearchBox_Search_Input\"]')\n",
      "<ipython-input-6-d5bd9e4fec90>:49: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_link_text('Latest').click()\n",
      "<ipython-input-6-d5bd9e4fec90>:52: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_link_text('Récent').click()\n",
      "<ipython-input-6-d5bd9e4fec90>:62: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  page_cards = driver.find_elements_by_xpath('//article[@data-testid=\"tweet\"]')\n",
      "C:\\anaconda\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:392: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>nickname</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kia haumaru to nono kiwis</td>\n",
       "      <td>@yoblackironman</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>kia haumaru to nono kiwisyoblackironman5hEn rp...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samer Awada</td>\n",
       "      <td>@sneaker_plug_la</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Samer Awadasneakerplugla8hEn rponse  SOLELINKS...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jay Baruchel</td>\n",
       "      <td>@BaruchelNDG</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Jay BaruchelBaruchelNDG8hI got a brand new pai...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tulumbacı</td>\n",
       "      <td>@ahmetcannguner</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Tulumbacahmetcannguner11hEn rponse  alniopules...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GDara / inactive like my bias</td>\n",
       "      <td>@badeth012</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>GDara  inactive like my biasbadeth01215hSandar...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tammy David</td>\n",
       "      <td>@tammydavid</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Tammy Davidtammydavid17hRooting for Uniqlo She...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NotKatarina.eth</td>\n",
       "      <td>@not_katarina</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>NotKatarinaethnotkatarina17h nike trademark to...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Metahero Club</td>\n",
       "      <td>@metaheroclub</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Metahero Clubmetaheroclub18hEn rponse  Metaher...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Metahero.io</td>\n",
       "      <td>@Metahero_io</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>MetaheroioMetaheroio18hEn rponse  RobGryn Nike...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blockworks</td>\n",
       "      <td>@Blockworks_</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>BlockworksBlockworks2 nov2 REPORTED IN CRYPTO ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Henry Rose</td>\n",
       "      <td>@thehankrose</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>Dr Henry Rosethehankrose2 novEn rponse  thomas...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zuro</td>\n",
       "      <td>@Richzuro</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>ZuroRichzuro2 novEn rponse  Ter0meIf you aint ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KIJANA YA PWANI</td>\n",
       "      <td>@itsmandevuuu</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>KIJANA YA PWANIitsmandevuuu2 novEn rponse  Lyn...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pkgguy</td>\n",
       "      <td>@Pkgguy1</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>PkgguyPkgguy12 novEn rponse  ClayTravisIm fair...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c.</td>\n",
       "      <td>@chinaamrqt</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>cchinaamrqt2 novlol hes part of the official n...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Words Matter</td>\n",
       "      <td>@BHacrosstheUS</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Words MatterBHacrosstheUS1 novEn rponse  brhpa...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Words Matter</td>\n",
       "      <td>@BHacrosstheUS</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Words MatterBHacrosstheUS1 novEn rponse  brhpa...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ian Miles Cheong @ stillgray.substack.com</td>\n",
       "      <td>Ian Miles Cheong @ stillgray.substack.com</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Ian Miles Cheong  stillgraysubstackcomstillgra...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MM</td>\n",
       "      <td>@mgmtesla</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>MMmgmtesla1 novEn rponse  MattWalshBlogAfter a...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A Big Dumb Idiot Man</td>\n",
       "      <td>@BigDumbIdiotMan</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>A Big Dumb Idiot ManBigDumbIdiotMan1 novEn rpo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Five Reasons Sports</td>\n",
       "      <td>@5ReasonsSports</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Five Reasons Sports5ReasonsSports1 novYes Tyle...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Kev</td>\n",
       "      <td>@cleantechkevin</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Kevcleantechkevin1 novEn rponse  aancientdream...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Todd Hudnall</td>\n",
       "      <td>@Todd_Hudnall</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Todd HudnallToddHudnall1 novEn rponse  DBHarri...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ana || new fic pinned (FOLKLORE AU!!!!)</td>\n",
       "      <td>@spanananano</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>ana  new fic pinned FOLKLORE AUspanananano1 no...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ana || new fic pinned (FOLKLORE AU!!!!)</td>\n",
       "      <td>@spanananano</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>ana  new fic pinned FOLKLORE AUspanananano1 no...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Reverend Dick Beans</td>\n",
       "      <td>@tipsyRandy</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Reverend Dick BeanstipsyRandy1 novEn rponse  m...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>@EvkProductions</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>EvkProductions31 octEn rponse  brfootball  et ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aims</td>\n",
       "      <td>@awakenotwoke17</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>Aimsawakenotwoke1731 octEn rponse  DailyMailNo...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Kate</td>\n",
       "      <td>@KateThea3</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>KateKateThea331 octEn rponse  whitesundesert  ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ChiΞfNFTOfficΞr.eth</td>\n",
       "      <td>@cryptolad_07</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>ChifNFTOfficrethcryptolad0731 octEn rponse  Th...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     username  \\\n",
       "0                   kia haumaru to nono kiwis   \n",
       "1                                 Samer Awada   \n",
       "2                                Jay Baruchel   \n",
       "3                                   Tulumbacı   \n",
       "4               GDara / inactive like my bias   \n",
       "5                                 Tammy David   \n",
       "6                             NotKatarina.eth   \n",
       "7                               Metahero Club   \n",
       "8                                 Metahero.io   \n",
       "9                                  Blockworks   \n",
       "10                             Dr. Henry Rose   \n",
       "11                                       Zuro   \n",
       "12                            KIJANA YA PWANI   \n",
       "13                                     Pkgguy   \n",
       "14                                         c.   \n",
       "15                               Words Matter   \n",
       "16                               Words Matter   \n",
       "17  Ian Miles Cheong @ stillgray.substack.com   \n",
       "18                                         MM   \n",
       "19                       A Big Dumb Idiot Man   \n",
       "20                        Five Reasons Sports   \n",
       "21                                        Kev   \n",
       "22                               Todd Hudnall   \n",
       "23    ana || new fic pinned (FOLKLORE AU!!!!)   \n",
       "24    ana || new fic pinned (FOLKLORE AU!!!!)   \n",
       "25                        Reverend Dick Beans   \n",
       "26                                        NaN   \n",
       "27                                       Aims   \n",
       "28                                       Kate   \n",
       "29                        ChiΞfNFTOfficΞr.eth   \n",
       "\n",
       "                                     nickname   timestamp  \\\n",
       "0                             @yoblackironman  2021-11-03   \n",
       "1                            @sneaker_plug_la  2021-11-03   \n",
       "2                                @BaruchelNDG  2021-11-03   \n",
       "3                             @ahmetcannguner  2021-11-03   \n",
       "4                                  @badeth012  2021-11-03   \n",
       "5                                 @tammydavid  2021-11-03   \n",
       "6                               @not_katarina  2021-11-03   \n",
       "7                               @metaheroclub  2021-11-03   \n",
       "8                                @Metahero_io  2021-11-03   \n",
       "9                                @Blockworks_  2021-11-02   \n",
       "10                               @thehankrose  2021-11-02   \n",
       "11                                  @Richzuro  2021-11-02   \n",
       "12                              @itsmandevuuu  2021-11-02   \n",
       "13                                   @Pkgguy1  2021-11-02   \n",
       "14                                @chinaamrqt  2021-11-02   \n",
       "15                             @BHacrosstheUS  2021-11-01   \n",
       "16                             @BHacrosstheUS  2021-11-01   \n",
       "17  Ian Miles Cheong @ stillgray.substack.com  2021-11-01   \n",
       "18                                  @mgmtesla  2021-11-01   \n",
       "19                           @BigDumbIdiotMan  2021-11-01   \n",
       "20                            @5ReasonsSports  2021-11-01   \n",
       "21                            @cleantechkevin  2021-11-01   \n",
       "22                              @Todd_Hudnall  2021-11-01   \n",
       "23                               @spanananano  2021-11-01   \n",
       "24                               @spanananano  2021-11-01   \n",
       "25                                @tipsyRandy  2021-11-01   \n",
       "26                            @EvkProductions  2021-10-31   \n",
       "27                            @awakenotwoke17  2021-10-31   \n",
       "28                                 @KateThea3  2021-10-31   \n",
       "29                              @cryptolad_07  2021-10-31   \n",
       "\n",
       "                                                tweet class  confidence  \n",
       "0   kia haumaru to nono kiwisyoblackironman5hEn rp...   pos        1.00  \n",
       "1   Samer Awadasneakerplugla8hEn rponse  SOLELINKS...   neg        1.00  \n",
       "2   Jay BaruchelBaruchelNDG8hI got a brand new pai...   neg        1.00  \n",
       "3   Tulumbacahmetcannguner11hEn rponse  alniopules...   neg        0.75  \n",
       "4   GDara  inactive like my biasbadeth01215hSandar...   pos        0.75  \n",
       "5   Tammy Davidtammydavid17hRooting for Uniqlo She...   pos        0.75  \n",
       "6   NotKatarinaethnotkatarina17h nike trademark to...   pos        0.75  \n",
       "7   Metahero Clubmetaheroclub18hEn rponse  Metaher...   pos        0.75  \n",
       "8   MetaheroioMetaheroio18hEn rponse  RobGryn Nike...   pos        1.00  \n",
       "9   BlockworksBlockworks2 nov2 REPORTED IN CRYPTO ...   neg        0.75  \n",
       "10  Dr Henry Rosethehankrose2 novEn rponse  thomas...   neg        1.00  \n",
       "11  ZuroRichzuro2 novEn rponse  Ter0meIf you aint ...   pos        1.00  \n",
       "12  KIJANA YA PWANIitsmandevuuu2 novEn rponse  Lyn...   pos        1.00  \n",
       "13  PkgguyPkgguy12 novEn rponse  ClayTravisIm fair...   pos        1.00  \n",
       "14  cchinaamrqt2 novlol hes part of the official n...   pos        1.00  \n",
       "15  Words MatterBHacrosstheUS1 novEn rponse  brhpa...   pos        1.00  \n",
       "16  Words MatterBHacrosstheUS1 novEn rponse  brhpa...   pos        1.00  \n",
       "17  Ian Miles Cheong  stillgraysubstackcomstillgra...   pos        0.75  \n",
       "18  MMmgmtesla1 novEn rponse  MattWalshBlogAfter a...   neg        0.75  \n",
       "19  A Big Dumb Idiot ManBigDumbIdiotMan1 novEn rpo...   neg        1.00  \n",
       "20  Five Reasons Sports5ReasonsSports1 novYes Tyle...   pos        1.00  \n",
       "21  Kevcleantechkevin1 novEn rponse  aancientdream...   neg        0.50  \n",
       "22  Todd HudnallToddHudnall1 novEn rponse  DBHarri...   neg        1.00  \n",
       "23  ana  new fic pinned FOLKLORE AUspanananano1 no...   pos        1.00  \n",
       "24  ana  new fic pinned FOLKLORE AUspanananano1 no...   pos        1.00  \n",
       "25  Reverend Dick BeanstipsyRandy1 novEn rponse  m...   pos        1.00  \n",
       "26  EvkProductions31 octEn rponse  brfootball  et ...   pos        0.75  \n",
       "27  Aimsawakenotwoke1731 octEn rponse  DailyMailNo...   pos        0.75  \n",
       "28  KateKateThea331 octEn rponse  whitesundesert  ...   neg        1.00  \n",
       "29  ChifNFTOfficrethcryptolad0731 octEn rponse  Th...   neg        0.50  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanum=30\n",
    "tweettt ='nike'\n",
    "serv='normal'\n",
    "\n",
    "#-------------------------------------\n",
    "\n",
    "# connexion vers twitter\n",
    "#----------------------------------------------------\n",
    "path =r'D:\\downloads\\chromedriver_win324/chromedriver.exe'\n",
    "\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(\"https://twitter.com/login\")\n",
    "sleep(4)\n",
    "username = driver.find_element_by_xpath('//input[@name=\"username\"]')\n",
    "username.send_keys('afifzak79764501')\n",
    "username.send_keys(Keys.RETURN)\n",
    "sleep(4)\n",
    "try:\n",
    "    password = driver.find_element_by_xpath('//input[@name=\"password\"]')\n",
    "    password.send_keys('afifzakaria1997')\n",
    "    password.send_keys(Keys.RETURN)\n",
    "except:\n",
    "    email = driver.find_element_by_xpath('//input[@name=\"text\"]')\n",
    "    email.send_keys('0629525883')\n",
    "    email.send_keys(Keys.RETURN)\n",
    "    sleep(4)\n",
    "    password = driver.find_element_by_xpath('//input[@name=\"password\"]')\n",
    "    password.send_keys('afifzakaria1997')\n",
    "    password.send_keys(Keys.RETURN)\n",
    "sleep(8)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "#query (entrer le nom du topic à rechercher dans l'input query)\n",
    "# ----------------------------------------------------\n",
    "search_input = driver.find_element_by_xpath('//input[@data-testid=\"SearchBox_Search_Input\"]')\n",
    "if serv=='normal':\n",
    "    searchfiltre='min_faves:50  -filter:links filter:replies lang:en '\n",
    "else:\n",
    "    searchfiltre='min_faves:50  -filter:links filter:replies '\n",
    "    valuemax=300\n",
    "    valuemax1=datanum\n",
    "    datanum=min(valuemax1,valuemax)\n",
    "search_input.send_keys(searchfiltre+ tweettt)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "sleep(6)\n",
    "try:\n",
    "    driver.find_element_by_link_text('Latest').click()\n",
    "except:\n",
    "    sleep(3)\n",
    "    driver.find_element_by_link_text('Récent').click()\n",
    "# ----------------------------------------------------\n",
    "\n",
    "#scraping and scrolling\n",
    "# ----------------------------------------------------\n",
    "data = []\n",
    "tweet_ids = set()\n",
    "last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "scrolling = True\n",
    "while scrolling:\n",
    "    page_cards = driver.find_elements_by_xpath('//article[@data-testid=\"tweet\"]')\n",
    "    for card in page_cards[-15:]:\n",
    "        tweet = get_tweet_data(card)\n",
    "        if tweet:\n",
    "            tweet_id = ''.join(tweet)\n",
    "            if tweet_id not in tweet_ids:\n",
    "                tweet_ids.add(tweet_id)\n",
    "                data.append(tweet)\n",
    "                if len(data) == datanum:\n",
    "                    scrolling = False\n",
    "                    break\n",
    "    scroll_attempt = 0\n",
    "    while True:\n",
    "        # check scroll position\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        sleep(2)\n",
    "        curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "        if last_position == curr_position:\n",
    "            scroll_attempt += 1\n",
    "            # end of scroll region\n",
    "            if scroll_attempt >= 3:\n",
    "                scrolling = False\n",
    "                break\n",
    "            else:\n",
    "                sleep(2)  # attempt another scroll\n",
    "        else:\n",
    "            last_position = curr_position\n",
    "            break\n",
    "    # close the web driver\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "#insertion des données dans un ensemble de données (dataset)\n",
    "# ----------------------------------------------------\n",
    "dr = pd.DataFrame(data, columns=['UserName', 'Handle', 'Timestamp', 'text', 'Cnts', 'Likes', 'Retweets'])\n",
    "\n",
    "dic = dict()\n",
    "for r in dr.keys():\n",
    "    dic[r] = []\n",
    "for r in dr.keys():\n",
    "    for l in dr[r]:\n",
    "        if l == '':\n",
    "            dic[r].append(np.nan)\n",
    "        elif l is None:\n",
    "            dic[r].append(np.nan)\n",
    "        else:\n",
    "            dic[r].append(l)\n",
    "df = pd.DataFrame()\n",
    "for r in dr.keys():\n",
    "    df[r] = dic[r]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "#insertion des données avant prétraitement dans une collection mongodb\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "#préatraitement\n",
    "# ----------------------------------------------------\n",
    "lst = []\n",
    "for l in df['text']:\n",
    "    if ('Replying to' in l) and ('@' in l):\n",
    "        d = l.split('@')[-1].lstrip().split(' ')\n",
    "        s = ''\n",
    "        for i in range(len(d)):\n",
    "            if i >= 1:\n",
    "                s = s + ' ' + d[i]\n",
    "        lst.append(s)\n",
    "    else:\n",
    "        lst.append(l)\n",
    "\n",
    "df['newtext'] = lst\n",
    "df['newtext'] = df['newtext'].replace('\\n', '').replace('@', '')\n",
    "\n",
    "\n",
    "\n",
    "lst = []\n",
    "for l in df['newtext']:\n",
    "    d = ''.join([i for i in str(l) if (ord(i) >= 65 and ord(i) <= 90) or (\n",
    "                ord(i) >= 97 and ord(i) <= 122) or i == ' ' or i.isdigit()])\n",
    "    lst.append(d)\n",
    "df['newtext2'] = lst\n",
    "lst = []\n",
    "for l in df['text']:\n",
    "    if ('Replying to' in l) and ('@' in l):\n",
    "        u = []\n",
    "        d = l.replace('Replying to', '').strip().split('@')\n",
    "        for i in range(len(d)):\n",
    "            if i >= 1 and i < (len(d) - 1):\n",
    "                u.append(d[i].replace('and', '').replace('\\n', ''))\n",
    "            else:\n",
    "                if i == (len(d) - 1):\n",
    "                    u.append(d[i].split(' ')[0].replace('and', '').replace('\\n', ''))\n",
    "        lst.append(u)\n",
    "    else:\n",
    "        lst.append(np.nan)\n",
    "\n",
    "df['receiver'] = lst\n",
    "df['Handle'] = df['Handle'].replace('@', '')\n",
    "\n",
    "\n",
    "\n",
    "df.rename(columns={'UserName': 'username',\n",
    "                   'Handle': 'nickname',\n",
    "                   'newtext2': 'tweet', 'Timestamp': 'timestamp'},\n",
    "          inplace=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.date\n",
    "df = df[df['tweet'].notnull()]\n",
    "df = df[df['tweet'] != '']\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#traduction si l'utilisateur a choisi le service \"translated\"\n",
    "# ----------------------------------------------------\n",
    "\n",
    "if serv=='translated':\n",
    "    p = dict()\n",
    "    p['translation'] = []\n",
    "    p['culture'] = []\n",
    "\n",
    "    for com in df['tweet']:\n",
    "\n",
    "        translator = google_translator()\n",
    "        try:\n",
    "            p['translation'].append(translator.translate(com, lang_tgt='en'))\n",
    "        except:\n",
    "            p['translation'].append(com)\n",
    "\n",
    "        try:\n",
    "            if len(translator.detect(com)) > 1:\n",
    "                p['culture'].append(translator.detect(com)[1])\n",
    "            else:\n",
    "                p['culture'].append('unknown')\n",
    "        except:\n",
    "            p['culture'].append('unknown')\n",
    "\n",
    "    df['tweet_translated'] = p['translation']\n",
    "    df['culture'] = p['culture']\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "#analyse des sentiments dans le cas du service \" normal \" et dans le cas du service \" translated\"\n",
    "# ----------------------------------------------------\n",
    "\n",
    "if serv=='normal':\n",
    "    s = []\n",
    "    for com in df['tweet']:\n",
    "        s.append(sentiment(com.lower()))\n",
    "else:\n",
    "    s = []\n",
    "    for com in df['tweet_translated']:\n",
    "        s.append(sentiment(com.lower()))\n",
    "\n",
    "dd = dict()\n",
    "dd['class'] = []\n",
    "dd['confidence'] = []\n",
    "for elem in s:\n",
    "    dd['class'].append(elem[0])\n",
    "    dd['confidence'].append(elem[1])\n",
    "df['class'] = dd['class']\n",
    "df['confidence'] = dd['confidence']\n",
    "df.drop(columns=['text', 'Cnts', 'Likes', 'Retweets', 'newtext'], inplace=True)\n",
    "del(df['receiver'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
